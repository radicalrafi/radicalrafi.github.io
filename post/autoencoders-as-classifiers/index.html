<!DOCTYPE html>
<html lang="en-US">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="description" content="a personal blog">
<meta name="keywords" content="minimalist,blog,goa,machine learning,deep learning,developer">

<base href="https://radicalrafi.github.io">

<title>rafi&#39;s den</title>

<meta name="generator" content="Hugo 0.30.2" />




<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">


<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400|Roboto+Slab:400,700|Roboto:300,300i,400,400i,500,500i,700,700i">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
<link rel="stylesheet" href="https://radicalrafi.github.io/css/main.css">




<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="theme-color" content="#ffffff">

</head>
<body lang="en-US">
<div class="container">


<header class="row text-left title">
  <h1 class="title">Autoencoders as Classifiers</h1>
</header>
<section id="category-pane" class="row meta">
  
  <div class="col-md-12">
    <h6 class="text-left meta">
        PUBLISHED ON NOV 17, 2017 
      
    </h6>
  </div>
  
</section>
<section id="content-pane" class="row">
  <div class="col-md-12 text-justify content">
    

<h1 id="exploring-autoencoders-as-classifiers-and-other-things">Exploring Autoencoders as classifiers and other things</h1>

<h2 id="t-o-c">T.O.C</h2>

<ul>
<li><p>Introduction</p></li>

<li><p>What is an autoencoder ?</p></li>

<li><p>Building some variants in Keras</p></li>

<li><p>Pretraining and Classification using Autoencoders on MNIST</p></li>
</ul>

<h3 id="introduction">Introduction</h3>

<p>Autoencoders are a special case of neural networks,the intuition behind them is actually very beautiful</p>

<p><img src="https://screenshots.firefoxusercontent.com/images/f2bde64b-69c2-477e-8654-61cfa9535a2f.png" alt="excerpt of Salakhutdinov &amp; Hinton Paper" />
The idea behind autoencoders is actually very simple, think of any object a table for example .</p>

<p>Now to describe a table you can use as much <em>features as you like</em> It has 4 or more legs,it&rsquo;s made of wood ,it&rsquo;s rounded sometimes square,sometimes an ellipse &hellip; now a more <em>compressed</em> description can be : It&rsquo;s a smooth surface standing on 3 or more legs .</p>

<blockquote>
<p>The idea is that can we learn a lower dimenisional,simpler representation of our data  ?</p>
</blockquote>

<p>Training autoencoders is an inference &ndash;&gt; generative process , first we learn smaller and smaller representations then we start reconstructing them so as the output is similar to the input .</p>

<h3 id="what-is-an-autoencoder">What is an autoencoder</h3>

<p><em>from the Deep Learning Book</em></p>

<blockquote>
<p>An autoencoder is a neural network that is trained to attempt to copy its input to its output. Internally,
 it has a hidden layer h that describes a code used to represent the input. The network may be viewed as consi sting of two parts: an encoder function
 h=f(x) and a decoder that produces a reconstruction r=g(h) .</p>
</blockquote>

<p>Autoencoders are constrained so not to learn to <em>only copy</em> but rather to construct &amp; deconstruct the input .
because it&rsquo;s constrained by this reduction it is forced to make priorities on which features of the input
to learn ? which are useful ? and which are the most important .</p>

<p>This restriction that we impose is in the form of tighter and smaller layers,it&rsquo;s gradually forced to learn less and less in the <strong>encoding</strong> phase and more and more in the <strong>decoding</strong> phase .</p>

<p><img src="https://team.mail.ru/wp-content/uploads/2017/05/Neural-Networks4.png" alt="stacked" /></p>

<ul>
<li>for a more in depth treatment ,I suggest <a href="http://www.deeplearningbook.org/contents/autoencoders.html">Chapter 14 - Deep Learning Book</a></li>
</ul>

<h3 id="implementation-training">Implementation &amp; Training</h3>

<ul>
<li>the following implementations can be seen in full <a href="https://github.com/radicalrafi/deep-learning-notes">here</a></li>
</ul>

<p>Let&rsquo;s implement a simple autoencoder in keras ,training it on MNIST .</p>

<pre><code class="language-python">input_img = Input(shape=(784,))
encoded = Dense(128, activation='relu')(input_img)
encoded = Dense(64, activation='relu')(encoded)
encoded = Dense(32, activation='relu')(encoded)
encoded = Dense(16, activation='relu')(encoded) #the latent layer 
decoded = Dense(64, activation='relu')(encoded)
decoded = Dense(128, activation='relu')(decoded)
decoded = Dense(784, activation='sigmoid')(decoded)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')

autoencoder.fit(x_train, x_train,
                epochs=100,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))

</code></pre>

<p>Running the code up will train the network (you can always summarize it using .summary() method in keras)</p>

<p><img src="https://screenshots.firefoxusercontent.com/images/d7bd8d7d-d09b-4097-9bcb-defb31bcb88a.png" alt="mnist-before-after" /></p>

<p>The upper row pictures shows MNIST the under ones are the reconstructed pictures by the autoencoder you can see clearly how good it can reconstruct data like images .</p>

<p>There are more ways to use Autoencoders you can use Variational Autoencoder (Probobalistic),Denoising Autoencoders (Training the network to remove or filter noise (for example gaussian noise on pictures&hellip;) but one I want to show you is using them as feature learners and classifiers .</p>

<p>In essence any neural network can be turned to a classifier by adding a Sigmoid or Softmax output layer for Binary or Multi Class problems ,when training the network we train it in a normal manner then we remove the decoder part and simply replace it with a softmax layer .</p>

<p><img src="http://ufldl.stanford.edu/wiki/images/thumb/0/0e/Stacked_SparseAE_Features1.png/400px-Stacked_SparseAE_Features1.png" alt="train-ae" /></p>

<p><img src="http://ufldl.stanford.edu/wiki/images/thumb/b/bf/Stacked_SparseAE_Features2.png/400px-Stacked_SparseAE_Features2.png" alt="supervise-ae" /></p>

<blockquote>
<p>Make sure to freeze your layers as not to mess with them</p>
</blockquote>

<p>Once this change is into effect we train the network for a second time but we keep all the encoder weights frozen so as to only tune the output layer .</p>

<p>This way we can form a classifier that only uses a small set of features you can take it further by actually using it as a feature extractor network for example .</p>

<pre><code class="language-python">output = Dense(10,activation='softmax')(encoded)
autoencoder = Model(input_img,output)
autoencoder.compile(optimizer='adadelta',loss='categorical_crossentropy',metrics=['accuracy'])
autoencoder.fit(x_train,y_train,epochs=5,batch_size=32)
score = autoencoder.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
</code></pre>

<p><img src="https://screenshots.firefoxusercontent.com/images/8f8e488a-d2f7-46b5-8782-8deabb2b7f04.png" alt="training-result" /></p>

<pre><code class="language-python"># making a prediction

m = x_val[0]
pred = autoencoder.predict(m.reshape(1,784)
pred = pred.argmax(axis=-1)
</code></pre>

<p><img src="https://screenshots.firefoxusercontent.com/images/ca0f690d-57b7-4ad2-a7ba-b953acfaf5f8.png" alt="sample" /></p>

<p>after executing this code we get pred is equal to 7 .</p>

<p>You can test this code in countless way ,try reducing the latent space to a denser layer say 4 nodes or just 2</p>

  </div>
</section>
<section id="tag-pane" class="row meta">
  
  <div class="col-md-12">
    <h6 class="text-right meta">
      
    </h6>
  </div>
  
</section>








<section id="menu-pane" class="row menu text-center">
  
  
  <span><a class="menu-item" href="https://radicalrafi.github.io/post/first/">&lt; prev | </a></span>
  
  
  <span><a class="menu-item" href="/post">post</a></span>
  
  
  
  <h4 class="text-center"><a class="menu-item" href="https://radicalrafi.github.io">home</a></h4>
</section>



<footer class="row text-center footer">
  <hr />
  
  <h6 class="text-center copyright">Â© 2017. A.B. <a href="http://creativecommons.org/licenses/by/3.0/">Some Rights Reserved</a>.</h6>
  
  <h6 class="text-center powered">Powered by <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/shenoybr/hugo-goa">Goa</a>.</h6>
  
  
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  

<script type="text/javascript">
hljs.initHighlightingOnLoad();
</script>




<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'XYZ', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="js/main.js"></script>
</body>
</html>


